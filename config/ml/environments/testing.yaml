# Testing Environment Configuration
# Configuration for testing environment ML services

environment:
  name: "testing"
  description: "Testing environment for ML services validation and testing"
  
  infrastructure:
    cluster:
      type: "kubernetes"
      namespace: "ml-testing"
      node_pool: "ml-testing-nodes"
      resources:
        cpu_limit: "4"
        memory_limit: "8Gi"
        storage_limit: "50Gi"
        
    networking:
      ingress:
        enabled: true
        host: "ml-testing.company.com"
        tls:
          enabled: true
          cert_manager: "letsencrypt"
      service_mesh:
        enabled: false
        
    storage:
      persistent_volumes:
        - name: "ml-models"
          size: "20Gi"
          storage_class: "standard"
          access_mode: "ReadWriteMany"
        - name: "ml-data"
          size: "50Gi"
          storage_class: "standard"
          access_mode: "ReadWriteMany"
        - name: "ml-logs"
          size: "10Gi"
          storage_class: "standard"
          access_mode: "ReadWriteMany"
          
  services:
    mlflow:
      enabled: true
      replicas: 1
      resources:
        requests:
          cpu: "200m"
          memory: "512Mi"
        limits:
          cpu: "1000m"
          memory: "2Gi"
      database:
        type: "postgresql"
        host: "postgres-testing"
        port: 5432
        database: "mlflow_testing"
        username: "mlflow"
        password_secret: "mlflow-postgres-password"
      storage:
        type: "s3"
        bucket: "mlflow-testing"
        region: "us-west-2"
      tracking_uri: "http://mlflow-testing:5000"
      
    feast:
      enabled: true
      replicas: 1
      resources:
        requests:
          cpu: "200m"
          memory: "512Mi"
        limits:
          cpu: "1000m"
          memory: "2Gi"
      registry:
        type: "s3"
        bucket: "feast-testing"
        path: "registry/"
      online_store:
        type: "redis"
        host: "redis-testing"
        port: 6379
        db: 0
      offline_store:
        type: "bigquery"
        project: "ml-testing-project"
        dataset: "feast_testing"
        
    monitoring:
      prometheus:
        enabled: true
        replicas: 1
        resources:
          requests:
            cpu: "100m"
            memory: "256Mi"
          limits:
            cpu: "500m"
            memory: "1Gi"
        retention: "7d"
        scrape_interval: "60s"
        
      grafana:
        enabled: true
        replicas: 1
        resources:
          requests:
            cpu: "100m"
            memory: "256Mi"
          limits:
            cpu: "500m"
            memory: "1Gi"
        dashboards:
          - name: "ml-models"
            url: "http://grafana-testing:3000/d/ml-models"
          - name: "ml-pipelines"
            url: "http://grafana-testing:3000/d/ml-pipelines"
          - name: "ml-serving"
            url: "http://grafana-testing:3000/d/ml-serving"
            
      elasticsearch:
        enabled: true
        replicas: 1
        resources:
          requests:
            cpu: "200m"
            memory: "1Gi"
          limits:
            cpu: "1000m"
            memory: "4Gi"
        storage:
          size: "20Gi"
          storage_class: "standard"
          
      kibana:
        enabled: true
        replicas: 1
        resources:
          requests:
            cpu: "100m"
            memory: "256Mi"
          limits:
            cpu: "500m"
            memory: "1Gi"
            
    databases:
      postgresql:
        enabled: true
        replicas: 1
        resources:
          requests:
            cpu: "200m"
            memory: "512Mi"
          limits:
            cpu: "1000m"
            memory: "2Gi"
        storage:
          size: "10Gi"
          storage_class: "standard"
        database: "ml_testing"
        username: "ml_user"
        password_secret: "postgres-ml-password"
        
      redis:
        enabled: true
        replicas: 1
        resources:
          requests:
            cpu: "100m"
            memory: "256Mi"
          limits:
            cpu: "500m"
            memory: "1Gi"
        storage:
          size: "5Gi"
          storage_class: "standard"
        persistence:
          enabled: true
          snapshot_interval: "2h"
          
    message_queues:
      kafka:
        enabled: true
        replicas: 1
        resources:
          requests:
            cpu: "200m"
            memory: "512Mi"
          limits:
            cpu: "1000m"
            memory: "2Gi"
        storage:
          size: "20Gi"
          storage_class: "standard"
        topics:
          - name: "ml-predictions"
            partitions: 1
            replication_factor: 1
          - name: "ml-events"
            partitions: 1
            replication_factor: 1
          - name: "ml-monitoring"
            partitions: 1
            replication_factor: 1
            
  ml_services:
    model_serving:
      enabled: true
      replicas: 1
      resources:
        requests:
          cpu: "200m"
          memory: "512Mi"
        limits:
          cpu: "1000m"
          memory: "2Gi"
      models:
        - name: "quality_assessment"
          version: "latest"
          endpoint: "/api/v1/quality/predict"
        - name: "maintenance"
          version: "latest"
          endpoint: "/api/v1/maintenance/predict"
        - name: "process_optimization"
          version: "latest"
          endpoint: "/api/v1/process/optimize"
          
    feature_store:
      enabled: true
      replicas: 1
      resources:
        requests:
          cpu: "200m"
          memory: "512Mi"
        limits:
          cpu: "1000m"
          memory: "2Gi"
      features:
        - name: "process_features"
          ttl: "1h"
        - name: "sensor_features"
          ttl: "1h"
        - name: "material_features"
          ttl: "24h"
        - name: "environmental_features"
          ttl: "1h"
          
    model_training:
      enabled: true
      replicas: 1
      resources:
        requests:
          cpu: "500m"
          memory: "2Gi"
        limits:
          cpu: "2000m"
          memory: "8Gi"
      gpu:
        enabled: false
        type: "nvidia-tesla-t4"
        count: 0
      training_data:
        source: "s3://ml-training-data-testing/"
        format: "parquet"
        validation_split: 0.2
        test_split: 0.1
        
    model_evaluation:
      enabled: true
      replicas: 1
      resources:
        requests:
          cpu: "200m"
          memory: "1Gi"
        limits:
          cpu: "1000m"
          memory: "4Gi"
      evaluation_data:
        source: "s3://ml-evaluation-data-testing/"
        format: "parquet"
        metrics:
          - "accuracy"
          - "precision"
          - "recall"
          - "f1_score"
          - "mae"
          - "rmse"
          - "r2_score"
          
  data_sources:
    training_data:
      type: "s3"
      bucket: "ml-training-data-testing"
      region: "us-west-2"
      prefix: "training/"
      format: "parquet"
      compression: "snappy"
      
    validation_data:
      type: "s3"
      bucket: "ml-validation-data-testing"
      region: "us-west-2"
      prefix: "validation/"
      format: "parquet"
      compression: "snappy"
      
    test_data:
      type: "s3"
      bucket: "ml-test-data-testing"
      region: "us-west-2"
      prefix: "test/"
      format: "parquet"
      compression: "snappy"
      
    production_data:
      type: "s3"
      bucket: "ml-production-data-testing"
      region: "us-west-2"
      prefix: "production/"
      format: "parquet"
      compression: "snappy"
      
  security:
    authentication:
      enabled: true
      type: "oauth2"
      provider: "auth0"
      client_id: "ml-testing-client"
      client_secret_secret: "auth0-client-secret"
      audience: "ml-testing-api"
      
    authorization:
      enabled: true
      type: "rbac"
      roles:
        - name: "ml_engineer"
          permissions: ["read", "write", "train", "deploy"]
        - name: "data_scientist"
          permissions: ["read", "write", "train"]
        - name: "operator"
          permissions: ["read", "predict"]
        - name: "admin"
          permissions: ["read", "write", "train", "deploy", "admin"]
          
    network_policies:
      enabled: true
      default_deny: true
      allowed_ingress:
        - from: "ml-testing-namespace"
        - from: "monitoring-namespace"
        - from: "ingress-namespace"
      allowed_egress:
        - to: "ml-testing-namespace"
        - to: "monitoring-namespace"
        - to: "external-s3"
        - to: "external-auth0"
        
    secrets_management:
      enabled: true
      type: "vault"
      vault_url: "https://vault-testing.company.com"
      role: "ml-testing-role"
      policies:
        - "ml-testing-read"
        - "ml-testing-write"
        
  monitoring:
    logging:
      level: "DEBUG"
      format: "json"
      fields:
        - "timestamp"
        - "level"
        - "message"
        - "service"
        - "request_id"
        - "user_id"
      retention_days: 7
      
    metrics:
      enabled: true
      collection_interval: "60s"
      retention_days: 7
      custom_metrics:
        - name: "model_accuracy"
          type: "gauge"
          labels: ["model_name", "version"]
        - name: "prediction_latency"
          type: "histogram"
          labels: ["model_name", "endpoint"]
        - name: "training_duration"
          type: "histogram"
          labels: ["model_name", "dataset_size"]
        - name: "feature_quality"
          type: "gauge"
          labels: ["feature_name", "feature_type"]
          
    alerting:
      enabled: true
      channels: ["slack", "email"]
      rules:
        - name: "high_error_rate"
          condition: "error_rate > 0.1"
          severity: "warning"
          duration: "10m"
        - name: "high_latency"
          condition: "prediction_latency_p95 > 2000"
          severity: "warning"
          duration: "10m"
        - name: "low_accuracy"
          condition: "model_accuracy < 0.7"
          severity: "warning"
          duration: "15m"
        - name: "high_memory_usage"
          condition: "memory_usage > 0.95"
          severity: "warning"
          duration: "10m"
        - name: "high_cpu_usage"
          condition: "cpu_usage > 0.95"
          severity: "warning"
          duration: "10m"
          
  backup:
    enabled: true
    schedule: "0 3 * * *"
    retention_days: 7
    destinations:
      - type: "s3"
        bucket: "ml-backup-testing"
        region: "us-west-2"
        prefix: "backups/"
    include:
      - "databases"
      - "models"
      - "configurations"
      - "logs"
    exclude:
      - "temp_files"
      - "cache"
      
  disaster_recovery:
    enabled: false
    rto: "8_hours"
    rpo: "4_hours"
    backup_frequency: "daily"
    test_frequency: "monthly"
    recovery_procedures:
      - name: "database_recovery"
        estimated_time: "4_hours"
        dependencies: ["postgresql", "redis"]
      - name: "model_recovery"
        estimated_time: "2_hours"
        dependencies: ["mlflow", "s3"]
      - name: "service_recovery"
        estimated_time: "2_hours"
        dependencies: ["kubernetes", "ingress"]
        
  testing:
    enabled: true
    test_types:
      - "unit_tests"
      - "integration_tests"
      - "load_tests"
      - "security_tests"
    test_data:
      source: "s3://ml-test-data-testing/"
      format: "parquet"
      size: "100MB"
    test_models:
      - name: "quality_assessment"
        test_cases: 100
        expected_accuracy: 0.8
      - name: "maintenance"
        test_cases: 100
        expected_accuracy: 0.85
      - name: "process_optimization"
        test_cases: 100
        expected_accuracy: 0.75
        
  deployment:
    strategy: "recreate"
    max_unavailable: 1
    max_surge: 1
    health_check:
      enabled: true
      initial_delay: 30
      period: 10
      timeout: 5
      failure_threshold: 3
      success_threshold: 1
    rollback:
      enabled: true
      automatic: false
      threshold: 0.2
      
  scaling:
    horizontal_pod_autoscaler:
      enabled: false
      min_replicas: 1
      max_replicas: 3
      target_cpu_utilization: 80
      target_memory_utilization: 90
      scale_up_stabilization: "1m"
      scale_down_stabilization: "5m"
    vertical_pod_autoscaler:
      enabled: false
      update_mode: "Auto"
      resource_policy:
        cpu: "100m-1000m"
        memory: "128Mi-2Gi"
