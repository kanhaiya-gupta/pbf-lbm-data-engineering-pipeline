# Performance Analysis Pipeline Configuration
# Pipeline for comprehensive model performance analysis

pipeline:
  name: "performance_analysis_pipeline"
  version: "1.0.0"
  description: "Comprehensive model performance analysis pipeline"
  
  stages:
    - name: "data_ingestion"
      description: "Ingest model predictions and ground truth data"
      component: "data_ingestion"
      inputs:
        - source: "model_predictions"
          path: "/data/predictions/"
          format: "parquet"
        - source: "ground_truth"
          path: "/data/ground_truth/"
          format: "parquet"
        - source: "test_data"
          path: "/data/test/"
          format: "parquet"
        - source: "model_metadata"
          path: "/data/model_metadata/"
          format: "json"
      outputs:
        - name: "analysis_data"
          path: "/data/pipeline/performance_analysis/input/"
          format: "parquet"
      parameters:
        batch_size: 10000
        parallel_workers: 4
        timeout_minutes: 60
        
    - name: "data_alignment"
      description: "Align predictions with ground truth data"
      component: "data_alignment"
      inputs:
        - name: "analysis_data"
          from_stage: "data_ingestion"
      outputs:
        - name: "aligned_data"
          path: "/data/pipeline/performance_analysis/aligned/"
          format: "parquet"
      parameters:
        alignment_strategy: "temporal_matching"
        time_tolerance: "1_minute"
        key_columns: ["sample_id", "timestamp", "equipment_id"]
        validation:
          enabled: true
          completeness_threshold: 0.95
          consistency_check: true
        error_handling: "exclude_mismatched"
        
    - name: "metric_calculation"
      description: "Calculate comprehensive performance metrics"
      component: "metric_calculation"
      inputs:
        - name: "aligned_data"
          from_stage: "data_alignment"
      outputs:
        - name: "performance_metrics"
          path: "/data/pipeline/performance_analysis/metrics/"
          format: "json"
      parameters:
        metrics:
          regression:
            - name: "mse"
              description: "Mean Squared Error"
            - name: "rmse"
              description: "Root Mean Squared Error"
            - name: "mae"
              description: "Mean Absolute Error"
            - name: "mape"
              description: "Mean Absolute Percentage Error"
            - name: "smape"
              description: "Symmetric Mean Absolute Percentage Error"
            - name: "r2"
              description: "R-squared"
            - name: "explained_variance"
              description: "Explained Variance Score"
            - name: "max_error"
              description: "Maximum Error"
          classification:
            - name: "accuracy"
              description: "Accuracy Score"
            - name: "precision"
              description: "Precision Score"
            - name: "recall"
              description: "Recall Score"
            - name: "f1_score"
              description: "F1 Score"
            - name: "auc_roc"
              description: "Area Under ROC Curve"
            - name: "auc_pr"
              description: "Area Under Precision-Recall Curve"
            - name: "log_loss"
              description: "Logarithmic Loss"
            - name: "matthews_corrcoef"
              description: "Matthews Correlation Coefficient"
          business_metrics:
            - name: "cost_savings"
              description: "Estimated cost savings from model predictions"
            - name: "quality_improvement"
              description: "Quality improvement percentage"
            - name: "downtime_reduction"
              description: "Equipment downtime reduction"
            - name: "defect_reduction"
              description: "Defect rate reduction"
        statistical_tests:
          enabled: true
          tests:
            - "t_test"
            - "wilcoxon_test"
            - "mann_whitney_u"
            - "ks_test"
        confidence_intervals:
          enabled: true
          confidence_level: 0.95
          method: "bootstrap"
          n_bootstrap: 1000
          
    - name: "error_analysis"
      description: "Analyze prediction errors and patterns"
      component: "error_analysis"
      inputs:
        - name: "aligned_data"
          from_stage: "data_alignment"
      outputs:
        - name: "error_analysis"
          path: "/data/pipeline/performance_analysis/error_analysis/"
          format: "json"
      parameters:
        analysis_types:
          - name: "residual_analysis"
            parameters:
              residual_plots: true
              qq_plots: true
              residual_distribution: true
              heteroscedasticity_test: true
          - name: "error_distribution"
            parameters:
              error_histogram: true
              error_statistics: true
              outlier_detection: true
              error_clustering: true
          - name: "bias_analysis"
            parameters:
              prediction_bias: true
              systematic_bias: true
              bias_by_feature: true
              bias_by_time: true
          - name: "variance_analysis"
            parameters:
              prediction_variance: true
              variance_by_feature: true
              variance_by_time: true
              variance_decomposition: true
        error_categorization:
          enabled: true
          categories:
            - "high_error"
            - "medium_error"
            - "low_error"
            - "outlier"
        error_correlation:
          enabled: true
          features: ["all"]
          correlation_threshold: 0.3
          
    - name: "feature_importance_analysis"
      description: "Analyze feature importance and contribution"
      component: "feature_importance_analysis"
      inputs:
        - name: "aligned_data"
          from_stage: "data_alignment"
      outputs:
        - name: "feature_importance"
          path: "/data/pipeline/performance_analysis/feature_importance/"
          format: "json"
      parameters:
        methods:
          - name: "permutation_importance"
            parameters:
              n_repeats: 10
              random_state: 42
          - name: "shap_values"
            parameters:
              sample_size: 1000
              max_features: 50
          - name: "feature_ablation"
            parameters:
              step_size: 0.1
              max_removal: 0.5
          - name: "correlation_analysis"
            parameters:
              correlation_threshold: 0.1
              feature_interactions: true
        stability_analysis:
          enabled: true
          bootstrap_samples: 100
          stability_threshold: 0.8
        feature_interactions:
          enabled: true
          max_interactions: 10
          interaction_threshold: 0.1
          
    - name: "temporal_analysis"
      description: "Analyze model performance over time"
      component: "temporal_analysis"
      inputs:
        - name: "aligned_data"
          from_stage: "data_alignment"
      outputs:
        - name: "temporal_analysis"
          path: "/data/pipeline/performance_analysis/temporal/"
          format: "json"
      parameters:
        time_windows:
          - "1_hour"
          - "1_day"
          - "1_week"
          - "1_month"
        analysis_types:
          - name: "performance_trend"
            parameters:
              trend_detection: true
              seasonality_analysis: true
              change_point_detection: true
          - name: "performance_stability"
            parameters:
              stability_metrics: true
              volatility_analysis: true
              regime_detection: true
          - name: "performance_degradation"
            parameters:
              degradation_detection: true
              degradation_rate: true
              early_warning: true
        statistical_tests:
          enabled: true
          tests:
            - "mann_kendall"
            - "pettitt"
            - "buishand"
        forecasting:
          enabled: true
          horizon: "1_week"
          method: "arima"
          
    - name: "comparative_analysis"
      description: "Compare performance across models and versions"
      component: "comparative_analysis"
      inputs:
        - name: "performance_metrics"
          from_stage: "metric_calculation"
      outputs:
        - name: "comparative_analysis"
          path: "/data/pipeline/performance_analysis/comparative/"
          format: "json"
      parameters:
        comparison_dimensions:
          - "model_version"
          - "model_type"
          - "training_data"
          - "feature_set"
          - "hyperparameters"
        statistical_tests:
          enabled: true
          tests:
            - "paired_t_test"
            - "wilcoxon_signed_rank"
            - "mcnemar_test"
        ranking_methods:
          - "performance_ranking"
          - "statistical_significance"
          - "business_impact"
        visualization:
          enabled: true
          plots:
            - "performance_comparison"
            - "statistical_significance"
            - "ranking_visualization"
            
    - name: "bias_fairness_analysis"
      description: "Analyze model bias and fairness"
      component: "bias_fairness_analysis"
      inputs:
        - name: "aligned_data"
          from_stage: "data_alignment"
      outputs:
        - name: "bias_fairness_analysis"
          path: "/data/pipeline/performance_analysis/bias_fairness/"
          format: "json"
      parameters:
        protected_attributes:
          - "material_type"
          - "equipment_id"
          - "build_orientation"
          - "operator_id"
        fairness_metrics:
          - "demographic_parity"
          - "equalized_odds"
          - "equal_opportunity"
          - "calibration"
          - "predictive_parity"
        bias_metrics:
          - "statistical_parity_difference"
          - "equalized_odds_difference"
          - "average_odds_difference"
          - "disparate_impact_ratio"
        statistical_tests:
          enabled: true
          tests:
            - "chi_square_test"
            - "fisher_exact_test"
            - "mann_whitney_u"
        bias_mitigation:
          enabled: true
          methods:
            - "preprocessing"
            - "inprocessing"
            - "postprocessing"
            
    - name: "report_generation"
      description: "Generate comprehensive performance analysis report"
      component: "report_generation"
      inputs:
        - name: "performance_metrics"
          from_stage: "metric_calculation"
        - name: "error_analysis"
          from_stage: "error_analysis"
        - name: "feature_importance"
          from_stage: "feature_importance_analysis"
        - name: "temporal_analysis"
          from_stage: "temporal_analysis"
        - name: "comparative_analysis"
          from_stage: "comparative_analysis"
        - name: "bias_fairness_analysis"
          from_stage: "bias_fairness_analysis"
      outputs:
        - name: "performance_report"
          path: "/data/pipeline/performance_analysis/reports/"
          format: "html"
      parameters:
        report_sections:
          - "executive_summary"
          - "performance_metrics"
          - "error_analysis"
          - "feature_importance"
          - "temporal_analysis"
          - "comparative_analysis"
          - "bias_fairness_analysis"
          - "recommendations"
        visualization:
          enabled: true
          plots:
            - "performance_dashboard"
            - "error_analysis_plots"
            - "feature_importance_plots"
            - "temporal_trends"
            - "comparative_charts"
            - "bias_fairness_plots"
        export_formats:
          - "html"
          - "pdf"
          - "json"
          - "csv"
        template: "performance_analysis_template.html"
        
    - name: "pipeline_monitoring"
      description: "Monitor performance analysis pipeline"
      component: "pipeline_monitoring"
      inputs:
        - name: "all_stages"
          from_stage: "*"
      outputs:
        - name: "monitoring_metrics"
          path: "/data/pipeline/performance_analysis/monitoring/"
          format: "json"
      parameters:
        metrics:
          - "pipeline_execution_time"
          - "data_processing_throughput"
          - "analysis_completeness"
          - "report_generation_time"
          - "resource_utilization"
        alerting:
          - name: "pipeline_failure"
            condition: "status == 'failed'"
            severity: "critical"
          - name: "analysis_incomplete"
            condition: "completeness < 0.95"
            severity: "warning"
          - name: "report_generation_failure"
            condition: "report_status == 'failed'"
            severity: "high"
        notifications:
          channels: ["email", "slack", "dashboard"]
          recipients: ["ml_team", "data_science_team"]

  scheduling:
    trigger: "schedule"
    schedule: "0 6 * * 0"  # Every Sunday at 6 AM
    timezone: "UTC"
    retry_policy:
      max_retries: 3
      retry_delay_minutes: 30
      exponential_backoff: true
      
  resources:
    compute:
      type: "spark_cluster"
      nodes: 4
      cores_per_node: 8
      memory_per_node: "32GB"
      storage: "200GB"
    gpu:
      enabled: false
    storage:
      type: "s3"
      bucket: "ml-performance-analysis"
      region: "us-west-2"
      
  environment:
    python_version: "3.9"
    dependencies:
      - "scikit-learn==1.3.0"
      - "pandas==2.0.3"
      - "numpy==1.24.3"
      - "matplotlib==3.7.2"
      - "seaborn==0.12.2"
      - "plotly==5.15.0"
      - "shap==0.42.1"
      - "fairlearn==0.9.0"
      - "scipy==1.11.1"
      - "statsmodels==0.14.0"
    environment_variables:
      AWS_DEFAULT_REGION: "us-west-2"
      LOG_LEVEL: "INFO"
      REPORT_TEMPLATE_PATH: "/templates/"
      
  monitoring:
    enabled: true
    metrics_collection:
      - "pipeline_execution_time"
      - "data_processing_throughput"
      - "analysis_completeness"
      - "report_generation_time"
      - "resource_utilization"
    logging:
      level: "INFO"
      format: "json"
      retention_days: 30
    alerting:
      enabled: true
      channels: ["email", "slack"]
      thresholds:
        execution_time_hours: 4
        failure_rate_percent: 5
        analysis_completeness: 0.95
