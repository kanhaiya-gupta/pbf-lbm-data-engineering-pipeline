# Defect Detection Training Pipeline Configuration
# ===============================================

pipeline:
  name: "defect_detection_training_pipeline"
  version: "1.0.0"
  description: "Training pipeline for real-time defect detection models"
  
  # Pipeline metadata
  metadata:
    author: "ML Team"
    created_date: "2024-01-01"
    last_updated: "2024-01-01"
    tags: ["defect_detection", "training", "lstm", "ispm"]

# Pipeline Stages
stages:
  - name: "data_ingestion"
    type: "data_loader"
    description: "Load and validate training data from multiple sources"
    config:
      sources:
        - type: "kafka"
          topic: "ispm_sensor_data"
          consumer_group: "training_consumer"
          batch_size: 1000
          timeout: 30000
        - type: "postgresql"
          table: "process_parameters"
          connection: "postgresql://pbf_dev:dev_password@postgres:5432/pbf_dev"
        - type: "mongodb"
          collection: "defect_classifications"
          connection: "mongodb://admin:password@mongodb:27017/pbf_data_lake"
      validation:
        schema_validation: true
        data_quality_checks: true
        outlier_detection: true
      output: "raw_data"
      
  - name: "data_preprocessing"
    type: "data_preprocessor"
    description: "Clean and preprocess raw data"
    config:
      cleaning:
        remove_duplicates: true
        handle_missing_values: "interpolate"
        outlier_detection: "iqr"
        outlier_threshold: 3.0
      normalization:
        method: "standard_scaler"
        fit_on_train: true
      feature_selection:
        enabled: true
        method: "mutual_information"
        n_features: 20
      output: "preprocessed_data"
      
  - name: "feature_engineering"
    type: "feature_processor"
    description: "Engineer features from preprocessed data"
    config:
      features_config: "config/ml/features/sensor_features/pyrometer_features.yaml"
      transformations:
        - type: "temporal_features"
          lags: [1, 2, 3, 6, 12, 24]
          windows: [6, 12, 24]
        - type: "statistical_features"
          aggregations: ["mean", "std", "min", "max", "median"]
          windows: [5, 10, 20]
        - type: "frequency_features"
          methods: ["fft", "spectral_centroid", "spectral_rolloff"]
          windows: [10, 20]
        - type: "cross_features"
          interactions: ["temperature*laser_power", "scan_speed*hatch_spacing"]
      validation:
        feature_quality_checks: true
        correlation_analysis: true
        variance_threshold: 0.01
      output: "engineered_features"
      
  - name: "data_splitting"
    type: "data_splitter"
    description: "Split data into train, validation, and test sets"
    config:
      splits:
        train: 0.7
        validation: 0.2
        test: 0.1
      strategy: "time_series_split"
      random_state: 42
      stratification: true
      target_column: "defect_type"
      output: "split_data"
      
  - name: "model_training"
    type: "model_trainer"
    description: "Train the defect detection model"
    config:
      model_config: "config/ml/models/defect_detection/real_time_defect_predictor.yaml"
      training_params:
        batch_size: 32
        epochs: 100
        learning_rate: 0.001
        early_stopping:
          patience: 10
          monitor: "val_loss"
          restore_best_weights: true
      validation:
        validation_split: 0.2
        validation_frequency: 1
      callbacks:
        - type: "early_stopping"
          patience: 10
        - type: "model_checkpoint"
          save_best_only: true
        - type: "reduce_lr_on_plateau"
          factor: 0.5
          patience: 5
      output: "trained_model"
      
  - name: "model_evaluation"
    type: "model_evaluator"
    description: "Evaluate model performance on test set"
    config:
      metrics:
        - "accuracy"
        - "precision_macro"
        - "recall_macro"
        - "f1_macro"
        - "confusion_matrix"
        - "classification_report"
        - "roc_auc"
      thresholds:
        min_accuracy: 0.90
        min_precision: 0.85
        min_recall: 0.85
        min_f1: 0.85
      validation:
        cross_validation: true
        folds: 5
        shuffle: true
      output: "evaluation_results"
      
  - name: "model_validation"
    type: "model_validator"
    description: "Validate model meets performance requirements"
    config:
      requirements:
        accuracy_threshold: 0.90
        precision_threshold: 0.85
        recall_threshold: 0.85
        f1_threshold: 0.85
        latency_threshold: 100
      tests:
        - type: "performance_test"
        - type: "latency_test"
        - type: "memory_test"
        - type: "robustness_test"
      output: "validation_results"
      
  - name: "model_registration"
    type: "model_registry"
    description: "Register model in MLflow registry"
    config:
      registry: "mlflow"
      stage: "staging"
      metadata:
        training_date: "{{ current_date }}"
        data_version: "{{ data_version }}"
        performance_metrics: "{{ evaluation_results }}"
        validation_results: "{{ validation_results }}"
        model_size: "{{ model_size }}"
        training_time: "{{ training_time }}"
      tags:
        model_type: "defect_detection"
        algorithm: "lstm"
        version: "1.0.0"
        environment: "development"
      output: "registered_model"

# Pipeline Scheduling
scheduling:
  trigger: "cron"
  schedule: "0 2 * * *"  # Daily at 2 AM
  timezone: "UTC"
  enabled: true
  
  # Retry configuration
  retry_policy:
    max_retries: 3
    backoff_factor: 2
    retry_delay: 300  # 5 minutes

# Resource Requirements
resources:
  cpu: "4"
  memory: "8Gi"
  gpu: "1"
  storage: "50Gi"
  
  # Resource limits
  limits:
    cpu: "8"
    memory: "16Gi"
    gpu: "2"
    storage: "100Gi"

# Environment Configuration
environment:
  python_version: "3.11"
  dependencies:
    - "tensorflow==2.16.1"
    - "scikit-learn==1.3.0"
    - "pandas==2.0.3"
    - "numpy==1.24.3"
    - "mlflow==2.9.2"
  
  # Environment variables
  env_vars:
    MLFLOW_TRACKING_URI: "http://mlflow:5000"
    MLFLOW_EXPERIMENT_NAME: "defect_detection_experiments"
    PYTHONPATH: "/app/src:/app/config"

# Error Handling
error_handling:
  # Retry policy
  retry_policy:
    max_retries: 3
    backoff_factor: 2
    retry_delay: 300
  
  # Failure handling
  failure_handling:
    strategy: "stop_on_failure"
    cleanup_on_failure: true
    preserve_logs: true
  
  # Notification
  notification:
    channels: ["email", "slack"]
    recipients: ["ml-team@company.com"]
    on_success: false
    on_failure: true
    on_retry: true

# Monitoring and Logging
monitoring:
  # Pipeline monitoring
  pipeline_monitoring:
    enabled: true
    metrics:
      - "execution_time"
      - "memory_usage"
      - "cpu_usage"
      - "stage_duration"
    
  # Model monitoring
  model_monitoring:
    enabled: true
    metrics:
      - "training_loss"
      - "validation_loss"
      - "accuracy"
      - "precision"
      - "recall"
      - "f1_score"
    
  # Data monitoring
  data_monitoring:
    enabled: true
    metrics:
      - "data_quality_score"
      - "feature_distribution"
      - "missing_value_rate"
      - "outlier_rate"

# Logging Configuration
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  handlers:
    - type: "console"
    - type: "file"
      filename: "/app/logs/defect_detection_training.log"
      max_bytes: 10485760  # 10MB
      backup_count: 5
  
  # Stage-specific logging
  stage_logging:
    enabled: true
    log_inputs: true
    log_outputs: false
    log_metrics: true
    log_artifacts: true

# Artifact Management
artifacts:
  # Artifact storage
  storage:
    type: "s3"
    bucket: "pbf-ml-artifacts"
    path: "defect_detection/training"
    compression: "gzip"
  
  # Artifact retention
  retention:
    enabled: true
    days: 30
    keep_best: 5
    keep_latest: 10
  
  # Artifact types
  types:
    - "model"
    - "metrics"
    - "plots"
    - "logs"
    - "configs"

# Pipeline Dependencies
dependencies:
  # Data dependencies
  data_dependencies:
    - source: "kafka"
      topic: "ispm_sensor_data"
      min_messages: 1000
    - source: "postgresql"
      table: "process_parameters"
      min_rows: 10000
    - source: "mongodb"
      collection: "defect_classifications"
      min_documents: 1000
  
  # Model dependencies
  model_dependencies:
    - type: "feature_store"
      name: "pyrometer_features"
      version: "latest"
    - type: "preprocessing"
      name: "standard_scaler"
      version: "latest"
  
  # Infrastructure dependencies
  infrastructure_dependencies:
    - service: "mlflow"
      endpoint: "http://mlflow:5000"
    - service: "redis"
      endpoint: "redis:6379"
    - service: "postgresql"
      endpoint: "postgres:5432"
