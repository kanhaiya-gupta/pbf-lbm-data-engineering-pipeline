# Build Parsing Module - PBF-LB/M Data Pipeline

## ðŸŽ¯ **Mission Statement**
Create a world-class build file parsing system that leverages the existing libSLM and PySLM libraries to extract, process, and analyze PBF-LB/M machine build files with maximum efficiency and minimal reinvention.

## ðŸš« **What We DON'T Do**
- âŒ **Reinvent file format parsing** - libSLM already handles this
- âŒ **Recreate 3D geometry processing** - PySLM already provides this
- âŒ **Build visualization from scratch** - PySLM has excellent visualization
- âŒ **Implement basic math operations** - Use existing libraries
- âŒ **Create new file I/O systems** - Use standard Python libraries

## âœ… **What We DO**
- âœ… **Orchestrate** libSLM and PySLM for maximum efficiency
- âœ… **Extract** specific data types (power, velocity, energy, paths)
- âœ… **Integrate** with our data pipeline architecture
- âœ… **Provide** clean, consistent APIs for our use cases
- âœ… **Bridge** between build files and our voxel/analysis systems

## ðŸ—ï¸ **Architecture Principles**

### **1. Leverage Existing Libraries**
```python
# âœ… GOOD: Use libSLM for file parsing
from libSLM import slm, translators

# âœ… GOOD: Use PySLM for analysis
import pyslm
from pyslm import Slm

# âŒ BAD: Don't reimplement file parsing
# def parse_mtt_file_from_scratch():  # NO!
```

### **2. Focus on Integration, Not Implementation**
- **libSLM**: Handles all file format parsing (.mtt, .sli, .cli, etc.)
- **PySLM**: Handles 3D analysis, visualization, and advanced processing
- **Our Code**: Orchestrates, extracts specific data, integrates with pipeline

### **3. Clean Separation of Concerns**
```
Build Files â†’ libSLM â†’ Our Extractors â†’ Data Pipeline â†’ Visualization
     â†“              â†“           â†“            â†“              â†“
  .mtt/.sli    Raw parsing   Specific    Structured    Voxel/3D
  .cli/.rea    & decoding    data        data          analysis
```

## ðŸ“ **Module Structure**

```
build_parsing/
â”œâ”€â”€ __init__.py                    # Factory functions and main exports
â”œâ”€â”€ base_parser.py                 # Abstract base class (minimal)
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ build_file_parser.py       # Main orchestrator (uses libSLM/PySLM)
â”‚   â”œâ”€â”€ format_detector.py         # Auto-detect formats (leverages libSLM)
â”‚   â””â”€â”€ metadata_extractor.py      # Extract metadata (from libSLM output)
â”œâ”€â”€ format_parsers/                # Format-specific wrappers
â”‚   â”œâ”€â”€ eos_parser.py              # EOS wrapper (uses libSLM.translators.eos)
â”‚   â”œâ”€â”€ mtt_parser.py              # MTT wrapper (uses libSLM.translators.mtt)
â”‚   â”œâ”€â”€ realizer_parser.py         # Realizer wrapper (uses libSLM.translators.realizer)
â”‚   â””â”€â”€ slm_parser.py              # SLM wrapper (uses libSLM.translators.slmsol)
â”œâ”€â”€ data_extractors/               # Extract specific data types
â”‚   â”œâ”€â”€ power_extractor.py         # Laser power analysis (from libSLM data)
â”‚   â”œâ”€â”€ velocity_extractor.py      # Scan velocity analysis (from libSLM data)
â”‚   â”œâ”€â”€ path_extractor.py          # Scan path geometry (from libSLM data)
â”‚   â”œâ”€â”€ energy_extractor.py        # Energy consumption (calculated from libSLM data)
â”‚   â””â”€â”€ layer_extractor.py         # Layer-specific data (from libSLM data)
â””â”€â”€ utils/
    â”œâ”€â”€ file_utils.py              # File handling (standard Python)
    â””â”€â”€ validation_utils.py        # Data validation (standard Python)
```

## ðŸ”§ **Implementation Strategy**

### **Phase 1: Foundation (libSLM Integration)**
1. **`base_parser.py`** - Minimal abstract base class
2. **`build_file_parser.py`** - Main orchestrator that uses libSLM
3. **Format parsers** - Thin wrappers around libSLM translators
4. **Basic data extraction** - Extract raw data from libSLM output

### **Phase 2: Data Extraction (PySLM Integration)**
1. **Power extractor** - Use PySLM for laser power analysis
2. **Velocity extractor** - Use PySLM for scan velocity analysis
3. **Path extractor** - Use PySLM for scan path geometry
4. **Energy extractor** - Calculate energy from PySLM data

### **Phase 3: Advanced Analysis (PySLM Features)**
1. **Build time analysis** - Use PySLM's build time features
2. **Heatmap generation** - Use PySLM's visualization
3. **Support structure analysis** - Use PySLM's support features
4. **Parametric studies** - Use PySLM's parametric capabilities

## ðŸ“‹ **Code Examples**

### **âœ… Correct Approach - Leverage libSLM**
```python
# base_parser.py
from abc import ABC, abstractmethod
from ..external import LIBSLM_AVAILABLE, PYSLM_AVAILABLE

class BaseBuildParser(ABC):
    def __init__(self):
        if not LIBSLM_AVAILABLE:
            raise RuntimeError("libSLM required for build parsing")
    
    @abstractmethod
    def parse_file(self, file_path: Path) -> Dict[str, Any]:
        """Parse build file using libSLM"""
        pass

# eos_parser.py
from libSLM.translators import eos

class EOSParser(BaseBuildParser):
    def parse_file(self, file_path: Path) -> Dict[str, Any]:
        # Use libSLM's EOS reader - don't reinvent!
        reader = eos.Reader()
        return reader.read(str(file_path))
```

### **âœ… Correct Approach - Leverage PySLM**
```python
# power_extractor.py
import pyslm
from pyslm import Slm

class PowerExtractor:
    def __init__(self):
        if not PYSLM_AVAILABLE:
            raise RuntimeError("PySLM required for power analysis")
    
    def analyze_power_distribution(self, build_data):
        # Use PySLM's analysis capabilities
        slm = Slm()
        return slm.analyze_power_distribution(build_data)
```

### **âŒ Wrong Approach - Reinventing**
```python
# âŒ DON'T DO THIS
def parse_mtt_file_manually(file_path):
    # Manually parsing MTT format - libSLM already does this!
    with open(file_path, 'rb') as f:
        # Hundreds of lines of custom parsing code...
        pass

# âŒ DON'T DO THIS  
def calculate_scan_velocity_from_scratch(coordinates, time):
    # PySLM already has velocity analysis!
    # Don't reinvent the wheel
    pass
```

## ðŸŽ¯ **Success Metrics**

1. **Leverage Ratio**: >90% of functionality should use libSLM/PySLM
2. **Code Efficiency**: Minimal custom code, maximum library usage
3. **Integration Quality**: Seamless integration with our data pipeline
4. **Performance**: Fast parsing using optimized libSLM/PySLM
5. **Maintainability**: Easy to maintain by leveraging stable libraries

## ðŸš€ **Key Benefits**

1. **World-Class Quality**: Leverage years of libSLM/PySLM development
2. **Fast Development**: Don't reinvent, just integrate
3. **Reliability**: Use battle-tested libraries
4. **Performance**: Optimized C++ (libSLM) and Python (PySLM) code
5. **Future-Proof**: Libraries are actively maintained and updated

## ðŸ“š **Dependencies**

- **libSLM**: C++ library with Python bindings for file parsing
- **PySLM**: High-level Python library for analysis and visualization
- **Our External Module**: Proper integration with libSLM/PySLM
- **Standard Python**: For utilities and integration code

## ðŸŽ¯ **Remember**
> "Don't reinvent the wheel. Use libSLM for parsing, PySLM for analysis, and focus on integration and orchestration."

This approach ensures we build a world-class system by leveraging existing world-class libraries rather than starting from scratch.
